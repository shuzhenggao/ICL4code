{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "from evall.bleu import corpus_bleu\n",
    "from evall.rouge import Rouge\n",
    "from evall.meteor import Meteor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracies(hypotheses, references, sources=None,filename=None, print_copy_info=False, mode='dev'):\n",
    "    _, bleu, ind_bleu = corpus_bleu(hypotheses, references)\n",
    "\n",
    "    rouge_calculator = Rouge()\n",
    "    rouge_l, ind_rouge = rouge_calculator.compute_score(references, hypotheses)\n",
    "    meteor_calculator = Meteor()\n",
    "    meteor, _ = meteor_calculator.compute_score(references, hypotheses)\n",
    "\n",
    "    return bleu * 100, rouge_l * 100, meteor * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum\n",
    "data = []\n",
    "with jsonlines.open('summary_results_.jsonl') as f:\n",
    "    for i in f:\n",
    "        data.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CodeX and GPT3.5 \n",
    "ref = {}\n",
    "hypo = {}\n",
    "count = 0\n",
    "for i in data:\n",
    "    prediction = i['choices'][0]['text'].strip() if i['choices'][0]['text'].strip() is not '' else 'get'\n",
    "    refence = i['label'] if i['label'].strip() is not '' else 'get'\n",
    "    if '\\n' in prediction:\n",
    "        prediction=prediction.split('\\n')[0]\n",
    "    hypo[count] = [prediction]\n",
    "    ref[count] = [refence]\n",
    "    count+=1\n",
    "bleu,rouge,meteor = eval_accuracies(hypo,ref)\n",
    "print(round(bleu,2),round(rouge,2),round(meteor,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ChatGPT\n",
    "ref = {}\n",
    "hypo = {}\n",
    "count = 0\n",
    "for i in data:\n",
    "    prediction = i['choices'][0]['message']['content'].strip() if i['choices'][0]['message']['content'].strip() is not '' else '.'\n",
    "    refence = i['label'] if i['label'].strip() is not '' else 'get'\n",
    "    if '\\n' in prediction:\n",
    "        prediction=prediction.split('\\n')[0]\n",
    "    hypo[count] = [prediction]\n",
    "    ref[count] = [refence]\n",
    "    count+=1\n",
    "bleu,rouge,meteor = eval_accuracies(hypo,ref)\n",
    "print(round(bleu,2),round(rouge,2),round(meteor,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bugfixing\n",
    "data = []\n",
    "with jsonlines.open('bugfixing_results_.jsonl') as f:\n",
    "    for i in f:\n",
    "        data.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CodeX and GPT3.5 \n",
    "ref = {}\n",
    "hypo = {}\n",
    "count = 0\n",
    "em=0\n",
    "for i in data:\n",
    "    prediction = i['choices'][0]['text'].strip() if i['choices'][0]['text'].strip() is not '' else '.'\n",
    "    refence = i['label'] if i['label'].strip() is not '' else 'get'\n",
    "    if '\\n' in prediction:\n",
    "        prediction=prediction.split('\\n')[0]\n",
    "    hypo[count] = [prediction]\n",
    "    ref[count] = [refence]\n",
    "    if ref[count][0] == hypo[count][0]:\n",
    "        em+=1\n",
    "    count+=1\n",
    "bleu,rouge,meteor = eval_accuracies(hypo,ref)\n",
    "print(round(bleu,2),round(100*em/len(data),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ChatGPT\n",
    "ref = {}\n",
    "hypo = {}\n",
    "count = 0\n",
    "em=0\n",
    "for i in data:\n",
    "    prediction = i['choices'][0]['message']['content'].strip() if i['choices'][0]['message']['content'].strip() is not '' else '.'\n",
    "    refence = i['label'] if i['label'].strip() is not '' else 'get'\n",
    "    if '\\n' in prediction:\n",
    "        prediction=prediction.split('\\n')[0]\n",
    "    hypo[count] = [prediction]\n",
    "    ref[count] = [refence]\n",
    "    if ref[count][0] == hypo[count][0]:\n",
    "        em+=1\n",
    "    count+=1\n",
    "bleu,rouge,meteor = eval_accuracies(hypo,ref)\n",
    "print(round(bleu,2),round(100*em/len(data),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
